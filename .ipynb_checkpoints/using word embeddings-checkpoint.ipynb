{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用Embedding层学习词嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将一个Embedding层实例化\n",
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(1000,64)  #Embedding层至少需要两个参数，标记的个数（这里是1000即最大索引值加一）和嵌入维度（这里是64）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载IMDB数据，准备用于Embedding层\n",
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "max_features = 10000    #作为特征的单词个数\n",
    "maxlen = 20             #在maxlen个单词后截断文本\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=max_features)      #将数据加载为整数列表\n",
    "\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train,maxlen=maxlen)  #将整数列表转换为形状为（samples,maxlen）的二维整数张量\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.6657 - acc: 0.6270 - val_loss: 0.6088 - val_acc: 0.7044\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.5322 - acc: 0.7551 - val_loss: 0.5195 - val_acc: 0.7364\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.4579 - acc: 0.7893 - val_loss: 0.4988 - val_acc: 0.7460\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.4242 - acc: 0.8059 - val_loss: 0.4930 - val_acc: 0.7516\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.4011 - acc: 0.8191 - val_loss: 0.4914 - val_acc: 0.7562\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.3827 - acc: 0.8306 - val_loss: 0.4951 - val_acc: 0.7568\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.3658 - acc: 0.8392 - val_loss: 0.4985 - val_acc: 0.7570\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.3497 - acc: 0.8481 - val_loss: 0.5023 - val_acc: 0.7560\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.3337 - acc: 0.8550 - val_loss: 0.5078 - val_acc: 0.7542\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.3177 - acc: 0.8644 - val_loss: 0.5126 - val_acc: 0.7542\n"
     ]
    }
   ],
   "source": [
    "#在IMDB数据上使用Embedding层和分类器\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "#指定Embedding层的最大输入长度，以便后面将嵌入输入展平，Embedding层激活的形状为(samples,maxlen,8)\n",
    "model.add(Embedding(10000,8,input_length=maxlen))\n",
    "model.add(Flatten())  #将三维的嵌入张量展平成形状为(samples,maxlen*8)的二维张量\n",
    "model.add(Dense(1,activation='sigmoid'))   \n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=10,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用预训练的词嵌入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "从原始文本到词嵌入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载IMDB数据的原始文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理IMDB原始数据的标签\n",
    "import os\n",
    "imdb_dir = 'aclImdb'\n",
    "train_dir = os.path.join(imdb_dir,'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg','pos']:\n",
    "    dir_name = os.path.join(train_dir,label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name,fname),encoding='utf-8')\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
